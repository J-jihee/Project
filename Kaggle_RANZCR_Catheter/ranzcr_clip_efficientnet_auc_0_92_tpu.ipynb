{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "ranzcr_clip_efficientnet_auc_0_92_tpu.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2l_YU4vv3APS"
      },
      "source": [
        "# RANZCR CLiP\n",
        "- [Basecode](https://www.kaggle.com/sohomdey/ranzcr-clip-efficientnet-auc-0-95-tpu)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJeF9NKA3APk"
      },
      "source": [
        "### Accelerator\n",
        "- TPU v3-8 [[doc](https://www.kaggle.com/docs/tpu)]  \n",
        "    - 참고 코드\n",
        "        - https://www.kaggle.com/xhlulu/ranzcr-efficientnet-tpu-training/data?select=tf_keras_efficientnet.py\n",
        "        - https://www.kaggle.com/bbalrangco/five-flowers-on-tpu-with-new-data-augmentation/edit\n",
        "\n",
        "### Module version\n",
        "- Seaborn version 0.10.0\n",
        "- Pandas version 1.1.5\n",
        "- Numpy version 1.17.5\n",
        "- cv2 version 4.41\n",
        "- Tenserflow version 2.4.1\n",
        "- Sklearn version 0.24.1\n",
        "- Tenserflow.keras version 2.4.0\n",
        "\n",
        "### Database\n",
        "- MongoDB server version 4.4.3\n",
        "- Python 3.9.1\n",
        "- Pycharm 2020.3.3\n",
        "- mongoDB Compass 1.25.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CXR1H2K3APm"
      },
      "source": [
        "## Workflow\n",
        "\n",
        "* Image preprocessing\n",
        "    * (present) Current architecture requires 3 channel inputs, need to fix it.\n",
        "    * (later)   Image preprocessing to improve the clarity of images\n",
        "    * (later)   More augmentation\n",
        "    * (later)   Different image sizes\n",
        "* Class balancing\n",
        "    * Weighted Loss Functions $\\rightarrow$ tf.keras.callbacks.ReduceLROnPlateau\n",
        "    * Oversampling $\\rightarrow$ tf.keras.callbacks.EarlyStopping\n",
        "* Architecture tuning\n",
        "* Ensembling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCF6zWVH3APo"
      },
      "source": [
        "## Install"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "nnrxfCRh3APp"
      },
      "source": [
        "# >> /dev/null : 표준 오류 출력만 무시\n",
        "! pip install -q efficientnet >> /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHbmCFK63APr"
      },
      "source": [
        "## Import modules\n",
        "\n",
        "- 평가 메트릭 AUC : tf.keras.metrics.AUC\n",
        "- 교차 검증 : KFold (미사용)\n",
        "- [mixed_precision](https://www.tensorflow.org/guide/mixed_precision?hl=ko) : 훈련 중에 모델에서 16-bit 및 32-bit 부동 소수점 유형을 모두 사용하여 더 빠르게 실행하고 메모리를 적게 사용 (TPU 환경 'bfloat16' 사용)\n",
        "- backend : [tensorflow.keras.backend 사용](https://i-am-eden.tistory.com/2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "UZdqi2aR3APs"
      },
      "source": [
        "import os\n",
        "import re\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "# from sklearn.metrics import classification_report, roc_auc_score, roc_curve, confusion_matrix\n",
        "\n",
        "import efficientnet.tfkeras as efn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13CdSLjR3APt"
      },
      "source": [
        "## Set path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Euasqji_3APv"
      },
      "source": [
        "DATA_PATH = '/kaggle/input/ranzcr-clip-catheter-line-classification'\n",
        "\n",
        "MODEL_PATH = '/kaggle/working/models'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "0lZF_idv3APw",
        "outputId": "d714954d-dacc-4b25-e257-d41087babc8f"
      },
      "source": [
        "#tf record 파일 갯수 확인\n",
        "\n",
        "NUM_TF_RECS = len(os.listdir(f'{DATA_PATH}/train_tfrecords'))\n",
        "\n",
        "print(NUM_TF_RECS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hTNT-_W3APz"
      },
      "source": [
        "## Set parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "O_TY5WAU3AP0"
      },
      "source": [
        "DEVICE = 'TPU' # ['CPU' GPU' 'TPU']\n",
        "\n",
        "ENABLE_MIXED_PRECISION = True # [True False]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ITMlkTNf3AP0"
      },
      "source": [
        "SEED = 42\n",
        "\n",
        "FOLDS = 5 \n",
        "\n",
        "EFF_NET = 'B0' # ['B0',B1','B2',B3','B4',B5','B6',B7']\n",
        "# effnets = {'B0': efn.EfficientNetB0,'B1': efn.EfficientNetB1,'B2': efn.EfficientNetB2,'B3': efn.EfficientNetB3,'B4': efn.EfficientNetB4,'B5': efn.EfficientNetB5,'B6': efn.EfficientNetB6,'B7': efn.EfficientNetB7}\n",
        "\n",
        "if EFF_NET=='B0':\n",
        "    IMG_SIZE = 224\n",
        "elif EFF_NET=='B1':\n",
        "    IMG_SIZE = 240\n",
        "elif EFF_NET=='B2':\n",
        "    IMG_SIZE = 260\n",
        "elif EFF_NET=='B3':\n",
        "    IMG_SIZE = 300\n",
        "elif EFF_NET=='B4':\n",
        "    IMG_SIZE = 380\n",
        "elif EFF_NET=='B5':\n",
        "    IMG_SIZE = 456\n",
        "elif EFF_NET=='B6':\n",
        "    IMG_SIZE = 528\n",
        "elif EFF_NET=='B7':\n",
        "    IMG_SIZE = 600\n",
        "\n",
        "\n",
        "BATCH_SIZE = 32 # [8, 16, 32, 64, 128, 256, 512]\n",
        "\n",
        "EPOCHS = 25\n",
        "\n",
        "VERBOSE = 2 # [0: silent, 1: progress bar, 2: single line]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59k8Ed3x3AP1"
      },
      "source": [
        "## Setup devices and settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Iy9qvm4s3AP2"
      },
      "source": [
        "# For kaggle tpus (Need Internet)\n",
        "from kaggle_datasets import KaggleDatasets\n",
        "if DEVICE == 'TPU':\n",
        "    DATA_PATH = KaggleDatasets().get_gcs_path(DATA_PATH.split('/')[-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "nCyjZOq53AP3",
        "outputId": "a343548c-c6ae-4860-f096-e06111ae681d"
      },
      "source": [
        "if DEVICE == 'CPU':\n",
        "\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "    print('\\nUsing Default Distribution Strategy  for CPU')\n",
        "\n",
        "\n",
        "if DEVICE == 'GPU':\n",
        "\n",
        "    gpu_accelerarors = tf.config.list_physical_devices('GPU')\n",
        "        \n",
        "    if len(gpu_accelerarors) > 1:\n",
        "        strategy = tf.distribute.MirroredStrategy()\n",
        "        print(f'Number of GPUs available: {len(gpu_accelerarors)}')\n",
        "        print('\\n Using Mirrored Distribution Strategy')\n",
        "        \n",
        "    else:\n",
        "        strategy = tf.distribute.get_strategy()\n",
        "        if len(gpu_accelerarors) == 1:\n",
        "            print(f'Number of GPUs available: 1')\n",
        "            print('\\nUsing Default Distribution Strategy for GPU')\n",
        "        else:\n",
        "            print('ERROR: GPU not available')\n",
        "            print('\\nUsing Default Distribution Strategy  for CPU')\n",
        "        \n",
        "if DEVICE == 'TPU':\n",
        "\n",
        "    try:\n",
        "        resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "        tf.config.experimental_connect_to_cluster(resolver)\n",
        "        tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "        strategy = tf.distribute.experimental.TPUStrategy(resolver)\n",
        "        tpu_accelerarors = tf.config.list_logical_devices('TPU')\n",
        "        print(f'Number of TPU cores available: {len(tpu_accelerarors)}')\n",
        "        print(f'\\nUsing TPU Distribution Strategy')\n",
        "        \n",
        "    except:\n",
        "        print('ERROR: TPU not available')\n",
        "        print('\\nUsing Default Distribution Strategy for CPU')\n",
        "        strategy = tf.distribute.get_strategy()\n",
        "        \n",
        "        \n",
        "if ENABLE_MIXED_PRECISION:\n",
        "    \n",
        "    print('\\nMixed Precision enabled:')\n",
        "    \n",
        "    if DEVICE == 'GPU':\n",
        "        policy = mixed_precision.Policy('mixed_float16')\n",
        "        \n",
        "    if DEVICE == 'TPU':\n",
        "        policy = mixed_precision.Policy('mixed_bfloat16')\n",
        "        \n",
        "    mixed_precision.set_policy(policy)\n",
        "    \n",
        "    print('\\t...Compute dtype: %s' % policy.compute_dtype)\n",
        "    print('\\t...Variable dtype: %s' % policy.variable_dtype)\n",
        "\n",
        "\n",
        "REPLICAS = strategy.num_replicas_in_sync\n",
        "print(f'\\nREPLICAS: {REPLICAS}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of TPU cores available: 8\n",
            "\n",
            "Using TPU Distribution Strategy\n",
            "\n",
            "Mixed Precision enabled:\n",
            "\t...Compute dtype: bfloat16\n",
            "\t...Variable dtype: float32\n",
            "\n",
            "REPLICAS: 8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "RM5S9qHc3AP5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4zjphNR3AP6"
      },
      "source": [
        "## Helper functions\n",
        "- 클래스 Dataset : \n",
        "    - 클래스 변수 : tf.io.FixedLenFeature([], tf.string) : 고정길이 입력기능 (컬럼별로 지정)\n",
        "    - parse_function, generator : [TFRecord 파일 사용](https://limjun92.github.io/assets/TensorFlow%202.0%ED%8A%9C%ED%86%A0%EB%A6%AC%EC%96%BC/3.%20%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EB%A1%9C%EB%93%9C%20%EB%B0%8F%20%EC%82%AC%EC%A0%84%20%EC%B2%98%EB%A6%AC/%5B%ED%8A%9C%ED%86%A0%EB%A6%AC%EC%96%BC8%5D%20TFRecord%EC%99%80%20tf.Example/)\n",
        "    - augment_function : 상하반전, 좌우반전, 채도조절, 명도조절\n",
        "    \n",
        "- create_model\n",
        "    ```\n",
        "    model = tf.keras.Sequential([\n",
        "    effnets[EFF_NET](\n",
        "        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
        "        weights='imagenet',\n",
        "        include_top=False,\n",
        "        drop_connect_rate=0.7),\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Dense(11, activation='sigmoid')\n",
        "    ])\n",
        "    \n",
        "    ```\n",
        "- compile_model\n",
        "    ```\n",
        "    model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(lr=0.0001),\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=0.05),\n",
        "    metrics=[tf.keras.metrics.AUC(name='auc', multi_label=True)])\n",
        "    \n",
        "    ```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "nhXK5LYe3AP7"
      },
      "source": [
        "class Dataset:\n",
        "    \n",
        "    feature_description = {\n",
        "        \"StudyInstanceUID\"           : tf.io.FixedLenFeature([], tf.string),\n",
        "        \"image\"                      : tf.io.FixedLenFeature([], tf.string),\n",
        "        \"ETT - Abnormal\"             : tf.io.FixedLenFeature([], tf.int64), \n",
        "        \"ETT - Borderline\"           : tf.io.FixedLenFeature([], tf.int64), \n",
        "        \"ETT - Normal\"               : tf.io.FixedLenFeature([], tf.int64), \n",
        "        \"NGT - Abnormal\"             : tf.io.FixedLenFeature([], tf.int64), \n",
        "        \"NGT - Borderline\"           : tf.io.FixedLenFeature([], tf.int64), \n",
        "        \"NGT - Incompletely Imaged\"  : tf.io.FixedLenFeature([], tf.int64), \n",
        "        \"NGT - Normal\"               : tf.io.FixedLenFeature([], tf.int64), \n",
        "        \"CVC - Abnormal\"             : tf.io.FixedLenFeature([], tf.int64), \n",
        "        \"CVC - Borderline\"           : tf.io.FixedLenFeature([], tf.int64), \n",
        "        \"CVC - Normal\"               : tf.io.FixedLenFeature([], tf.int64), \n",
        "        \"Swan Ganz Catheter Present\" : tf.io.FixedLenFeature([], tf.int64),\n",
        "    }\n",
        "    \n",
        "    def __init__(self, image_size):\n",
        "        self.image_size = image_size\n",
        "        \n",
        "    def parse_function(self, example_proto):\n",
        "        example = tf.io.parse_single_example(example_proto, self.feature_description)\n",
        "        image = tf.io.decode_image(example['image'], channels=3)\n",
        "        label = [example['ETT - Abnormal'],\n",
        "                 example['ETT - Borderline'],\n",
        "                 example['ETT - Normal'],\n",
        "                 example['NGT - Abnormal'],\n",
        "                 example['NGT - Borderline'],\n",
        "                 example['NGT - Incompletely Imaged'],\n",
        "                 example['NGT - Normal'],\n",
        "                 example['CVC - Abnormal'],\n",
        "                 example['CVC - Borderline'],\n",
        "                 example['CVC - Normal'],\n",
        "                 example['Swan Ganz Catheter Present']]\n",
        "        return image, label \n",
        "    \n",
        "    def augment_function(self, image, label):\n",
        "        image = tf.image.random_flip_left_right(image)\n",
        "        image = tf.image.random_flip_up_down(image)\n",
        "        image = tf.image.random_contrast(image, 0.8, 1.2)\n",
        "        image = tf.image.random_brightness(image, 0.1)   \n",
        "        return image, label \n",
        "    \n",
        "    def process_function(self, image, label):\n",
        "        image.set_shape([None, self.image_size, self.image_size, 3])\n",
        "        label.set_shape([None, 11])\n",
        "        image = tf.image.resize(image, [self.image_size, self.image_size], 'bilinear')/255\n",
        "        return image, label\n",
        "            \n",
        "    def generator(self, files, batch_size=1, repeat=False, augment=False, shuffle=True):\n",
        "        AUTO = tf.data.experimental.AUTOTUNE\n",
        "        ds = tf.data.TFRecordDataset(files, num_parallel_reads=AUTO)\n",
        "        if shuffle: \n",
        "            opt = tf.data.Options()\n",
        "            opt.experimental_deterministic = False\n",
        "            ds = ds.with_options(opt)\n",
        "            ds = ds.shuffle(2000)\n",
        "        ds = ds.map(self.parse_function, num_parallel_calls=AUTO)\n",
        "        if repeat:\n",
        "            ds = ds.repeat()\n",
        "        if augment:\n",
        "            ds = ds.map(self.augment_function, num_parallel_calls=AUTO)\n",
        "        ds = ds.batch(batch_size)\n",
        "        ds = ds.map(self.process_function, num_parallel_calls=AUTO)\n",
        "        ds = ds.prefetch(AUTO)\n",
        "        return ds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "8fSxfuFT3AQA"
      },
      "source": [
        "def create_model(name, input_shape, classes, output_bias=None):\n",
        "    \n",
        "    # Dictionary mapping name to model function\n",
        "    \n",
        "    EFFICIENT_NETS = {'B0': efn.EfficientNetB0, \n",
        "                      'B1': efn.EfficientNetB1, \n",
        "                      'B2': efn.EfficientNetB2, \n",
        "                      'B3': efn.EfficientNetB3, \n",
        "                      'B4': efn.EfficientNetB4, \n",
        "                      'B5': efn.EfficientNetB5, \n",
        "                      'B6': efn.EfficientNetB6,\n",
        "                      'B7': efn.EfficientNetB7}\n",
        "    \n",
        "    # Output layer bias initialization\n",
        "    \n",
        "    if output_bias is None:\n",
        "        output_bias = 'zeros'\n",
        "    else:\n",
        "        output_bias = tf.keras.initializers.Constant(output_bias)\n",
        "        \n",
        "    \n",
        "    # Base model\n",
        "    \n",
        "    base_model = EFFICIENT_NETS[name](include_top=False, \n",
        "                                      weights='imagenet', \n",
        "                                      input_shape=input_shape)\n",
        "    \n",
        "    # Model\n",
        "    \n",
        "    inputs = tf.keras.Input(shape=input_shape)\n",
        "    x = base_model(inputs)\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "    x = tf.keras.layers.Dense(classes, bias_initializer=output_bias)(x)\n",
        "    outputs = tf.keras.layers.Activation('sigmoid', dtype='float32')(x) # Supports mixed-precision training\n",
        "    \n",
        "    model = tf.keras.Model(inputs, outputs)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "99ReGibq3AQC"
      },
      "source": [
        "def compile_model(model, lr=0.0001):\n",
        "    \n",
        "    optimizer = tf.keras.optimizers.Adam(lr=lr)\n",
        "    \n",
        "    loss = tf.keras.losses.BinaryCrossentropy(label_smoothing=0.05)\n",
        "        \n",
        "    metrics = [tf.keras.metrics.AUC(name='auc')]\n",
        "\n",
        "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXY7e8rT3AQD"
      },
      "source": [
        "### Callbacks\n",
        "- 모델 저장 (Validation AUC max 일 때)\n",
        "    - [tf.keras.callbacks.ModelCheckpoint](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint)\n",
        "- 모델의 개선이 없을 경우, Learning Rate를 조절해 모델의 개선을 유도\n",
        "    - [tf.keras.callbacks.ReduceLROnPlateau](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ReduceLROnPlateau) [[detail](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint)]\n",
        "- 모니터링 되는 모델의 지표 개선이 멈췄을 때 학습 중지\n",
        "    - [tf.keras.callbacks.EarlyStopping](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Xt4ojC6r3AQE"
      },
      "source": [
        "def create_callbacks(model_save_path, fold, verbose=1):\n",
        "    \n",
        "    verbose = int(verbose>0)\n",
        "    \n",
        "    if not os.path.exists(model_save_path):\n",
        "        os.makedirs(model_save_path)\n",
        "    \n",
        "    cpk_path = f'{model_save_path}/model-f{fold}.h5'\n",
        "\n",
        "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath=cpk_path,\n",
        "        monitor='val_auc',\n",
        "        mode='max',\n",
        "        save_best_only=True,\n",
        "        verbose=verbose\n",
        "    )\n",
        "\n",
        "    reducelr = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor='val_auc',\n",
        "        mode='max',\n",
        "        factor=0.1,\n",
        "        patience=3,\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    earlystop = tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_auc',\n",
        "        mode='max',\n",
        "        patience=10, \n",
        "        verbose=verbose\n",
        "    )\n",
        "    \n",
        "    \n",
        "    \n",
        "    callbacks = [checkpoint, reducelr, earlystop]\n",
        "    \n",
        "    return callbacks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-qRIAnz3AQF"
      },
      "source": [
        "#### count_items : 에포크의 스텝수 세는데 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ZSd75ZHo3AQF"
      },
      "source": [
        "def count_items(filenames):\n",
        "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
        "    return np.sum(n)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Df1ly6vb3AQG"
      },
      "source": [
        "## Main Training Pipeline\n",
        "\n",
        "- (현재) 교차검증이 아닌 한번만 학습하는 코드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "dEwAcfCL3AQH",
        "outputId": "b025353a-c843-43c5-a44a-ad3688a8d712"
      },
      "source": [
        "folds_val_auc = [None] * FOLDS # Store the validation auc for each fold\n",
        "\n",
        "skf = KFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\n",
        "\n",
        "print(f'Training...')\n",
        "\n",
        "for fold, (train_idx, valid_idx) in enumerate(skf.split(np.arange(NUM_TF_RECS))):\n",
        "    \n",
        "    print(f'\\n\\n{\"*\"*100} \\nFOLD: {fold+1}')\n",
        "    \n",
        "    # Input Pipeline ******************************************************\n",
        "    \n",
        "    train_files = tf.io.gfile.glob(f'{DATA_PATH}/train_tfrecords/{idx:02}*.tfrec' for idx in train_idx)\n",
        "    valid_files = tf.io.gfile.glob(f'{DATA_PATH}/train_tfrecords/{idx:02}*.tfrec' for idx in valid_idx)\n",
        "    \n",
        "    ds = Dataset(IMG_SIZE)\n",
        "    \n",
        "    train_ds = ds.generator(train_files, \n",
        "                            BATCH_SIZE, #*REPLICAS, \n",
        "                            repeat=True, \n",
        "                            augment=True, \n",
        "                            shuffle=True)\n",
        "\n",
        "    valid_ds = ds.generator(valid_files, \n",
        "                            BATCH_SIZE, #*REPLICAS,  \n",
        "                            repeat=False, \n",
        "                            augment=False, \n",
        "                            shuffle=False)\n",
        "    \n",
        "    # Calculate the steps_per_epoch\n",
        "    \n",
        "    steps_per_epoch = count_items(train_files)//(BATCH_SIZE) *2 #*REPLICAS) * 2\n",
        "    \n",
        "    \n",
        "    # Build Model ******************************************************\n",
        "    \n",
        "    tf.keras.backend.clear_session()\n",
        "        \n",
        "    with strategy.scope():\n",
        "        model = create_model(name=EFF_NET, \n",
        "                             input_shape=(IMG_SIZE,IMG_SIZE,3), \n",
        "                             classes=11)\n",
        "\n",
        "        model = compile_model(model, lr=0.0001)\n",
        "        model.summary()\n",
        "        \n",
        "    print(f'\\nModel initialized and compiled: EfficientNet-{EFF_NET}')\n",
        "    \n",
        "        \n",
        "    # Train ******************************************************\n",
        "    \n",
        "    callbacks = create_callbacks(MODEL_PATH, fold+1, verbose=VERBOSE)\n",
        "                                # MODEL_PATH = '/kaggle/working/models'\n",
        "\n",
        "    print(f'\\nModel training...\\n')\n",
        "    \n",
        "    history = model.fit(train_ds, \n",
        "                        epochs=EPOCHS, \n",
        "                        steps_per_epoch=steps_per_epoch,\n",
        "                        validation_data=valid_ds, \n",
        "                        callbacks=callbacks,\n",
        "                        verbose=VERBOSE)\n",
        "    \n",
        "    # Save acc for each fold in a list\n",
        "    folds_val_auc[fold] = max(history.history['val_auc'])\n",
        "    \n",
        "    print(f'\\nModel trained \\n\\nFOLD-{fold+1} Validation AUC = {folds_val_auc[fold]}')\n",
        "    \n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training...\n",
            "\n",
            "\n",
            "**************************************************************************************************** \n",
            "FOLD: 1\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "efficientnet-b0 (Functional) (None, 7, 7, 1280)        4049564   \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 11)                14091     \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 11)                0         \n",
            "=================================================================\n",
            "Total params: 4,063,655\n",
            "Trainable params: 4,021,639\n",
            "Non-trainable params: 42,016\n",
            "_________________________________________________________________\n",
            "\n",
            "Model initialized and compiled: EfficientNet-B0\n",
            "\n",
            "Model training...\n",
            "\n",
            "Epoch 1/25\n",
            "1410/1410 - 267s - loss: 0.3160 - auc: 0.9103 - val_loss: 0.2982 - val_auc: 0.9379\n",
            "\n",
            "Epoch 00001: val_auc improved from -inf to 0.93786, saving model to /kaggle/working/models/model-f1.h5\n",
            "Epoch 2/25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdONQs6N3AQH"
      },
      "source": [
        "## 학습훈련 그래프"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "-dQf7WvV3AQI"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_hist(hist):\n",
        "    plt.plot(hist.history['auc'], 'r', label='train auc')\n",
        "    plt.plot(hist.history['val_auc'], 'g', label='val auc')\n",
        "    plt.title(\"model auc\")\n",
        "    plt.ylabel(\"auc\")\n",
        "    plt.xlabel(\"epoch\")\n",
        "    plt.legend(loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_hist(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "NWXTJRTz3AQI"
      },
      "source": [
        "hist.history.key()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "aNEgAcCJ3AQJ"
      },
      "source": [
        "hist_df = pd.DataFrame(hist.history) \n",
        "hist_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "WVr-xmCi3AQJ"
      },
      "source": [
        "hist_df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "WuTDojuN3AQK"
      },
      "source": [
        "hist_df.to_csv(\"hist_{EFF_NET}.csv\", mode='w')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "gC3m3-td3AQK"
      },
      "source": [
        "from IPython.display import FileLink\n",
        "FileLink(r'df_name.csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}